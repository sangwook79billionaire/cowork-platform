#!/usr/bin/env python3
"""
ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° - Google News RSSë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì—‘ì…€ë¡œ ì €ì¥í•˜ê³  Firebaseì— ì—…ë¡œë“œ
"""

import os
import json
import requests
import feedparser
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv
import hashlib
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class NewsCollector:
    def __init__(self):
        """ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”"""
        self.base_url = "https://news.google.com/rss"
        self.collected_news = []
        self.firebase_db = None
        self._init_firebase()
    
    def _init_firebase(self):
        """Firebase ì´ˆê¸°í™”"""
        try:
            # Firebase Admin SDK ì´ˆê¸°í™”
            if not firebase_admin._apps:
                cred = credentials.Certificate("firebase/serviceAccountKey.json")
                firebase_admin.initialize_app(cred)
            
            self.firebase_db = firestore.client()
            print("âœ… Firebase ì—°ê²° ì„±ê³µ")
        except Exception as e:
            print(f"âŒ Firebase ì—°ê²° ì‹¤íŒ¨: {e}")
            self.firebase_db = None
    
    def search_google_news(self, keywords: str, language: str = "ko") -> List[Dict[str, Any]]:
        """Google News RSSì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘: {keywords}")
            
            # Google News RSS URL êµ¬ì„±
            encoded_keywords = requests.utils.quote(keywords)
            rss_url = f"{self.base_url}/search?q={encoded_keywords}&hl={language}&gl=KR&ceid=KR:ko"
            
            print(f"ğŸ“¡ RSS URL: {rss_url}")
            
            # RSS í”¼ë“œ íŒŒì‹±
            feed = feedparser.parse(rss_url)
            
            if not feed.entries:
                print("âŒ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            articles = []
            for i, entry in enumerate(feed.entries):
                # ì œëª©ì—ì„œ HTML íƒœê·¸ ì œê±°
                title = re.sub(r'<[^>]+>', '', entry.title)
                
                # ì„¤ëª…ì—ì„œ HTML íƒœê·¸ ì œê±°
                description = ""
                if hasattr(entry, 'summary'):
                    description = re.sub(r'<[^>]+>', '', entry.summary)
                
                # ì¶œì²˜ ì¶”ì¶œ
                source_name = "Google News"
                if hasattr(entry, 'source') and entry.source:
                    source_name = entry.source.title
                
                # ë§í¬ ì •ë¦¬
                link = entry.link
                if link.startswith('./'):
                    link = f"https://news.google.com{link[1:]}"
                
                article = {
                    'id': f"google-{hashlib.md5((title + link).encode()).hexdigest()[:8]}",
                    'title': title,
                    'description': description,
                    'content': description,  # AI ìš”ì•½ ëŒ€ì‹  description ì‚¬ìš©
                    'url': link,
                    'publishedAt': datetime.now().isoformat(),
                    'source': {
                        'name': source_name,
                        'id': 'google-news'
                    },
                    'keywords': keywords,
                    'collectedAt': datetime.now().isoformat()
                }
                
                articles.append(article)
            
            print(f"âœ… {len(articles)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            return articles
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def remove_duplicates(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen_titles = set()
        unique_articles = []
        
        for article in articles:
            # ì œëª© ì •ê·œí™” (íŠ¹ìˆ˜ë¬¸ì ì œê±°, ì†Œë¬¸ì ë³€í™˜)
            normalized_title = re.sub(r'[^\w\s]', '', article['title'].lower())
            
            if normalized_title not in seen_titles:
                seen_titles.add(normalized_title)
                unique_articles.append(article)
        
        print(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {len(articles)} â†’ {len(unique_articles)}")
        return unique_articles
    
    def save_to_excel(self, articles: List[Dict[str, Any]], filename: str = None) -> str:
        """ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"news_data_{timestamp}.xlsx"
        
        try:
            # DataFrame ìƒì„±
            df_data = []
            for article in articles:
                df_data.append({
                    'ID': article['id'],
                    'ì œëª©': article['title'],
                    'ì„¤ëª…': article['description'],
                    'ë‚´ìš©': article['content'],
                    'URL': article['url'],
                    'ì¶œì²˜': article['source']['name'],
                    'í‚¤ì›Œë“œ': article['keywords'],
                    'ìˆ˜ì§‘ì¼ì‹œ': article['collectedAt']
                })
            
            df = pd.DataFrame(df_data)
            
            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
            df.to_excel(filename, index=False, engine='openpyxl')
            print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            
            return filename
            
        except Exception as e:
            print(f"âŒ ì—‘ì…€ ì €ì¥ ì˜¤ë¥˜: {e}")
            return None
    
    def upload_to_firebase(self, articles: List[Dict[str, Any]], collection_name: str = "news") -> bool:
        """Firebase Firestoreì— ë‰´ìŠ¤ ë°ì´í„° ì—…ë¡œë“œ"""
        if not self.firebase_db:
            print("âŒ Firebase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            batch = self.firebase_db.batch()
            
            for article in articles:
                # ë¬¸ì„œ ID ìƒì„±
                doc_id = article['id']
                
                # Firestore ë¬¸ì„œ ì°¸ì¡°
                doc_ref = self.firebase_db.collection(collection_name).document(doc_id)
                
                # ë°°ì¹˜ì— ì¶”ê°€
                batch.set(doc_ref, article)
            
            # ë°°ì¹˜ ì»¤ë°‹
            batch.commit()
            
            print(f"âœ… Firebase ì—…ë¡œë“œ ì™„ë£Œ: {len(articles)}ê°œ ë¬¸ì„œ")
            return True
            
        except Exception as e:
            print(f"âŒ Firebase ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def collect_news(self, keywords: List[str], save_excel: bool = True, upload_firebase: bool = True) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜"""
        all_articles = []
        
        for keyword in keywords:
            print(f"\nğŸ” í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
            articles = self.search_google_news(keyword)
            all_articles.extend(articles)
        
        # ì¤‘ë³µ ì œê±°
        unique_articles = self.remove_duplicates(all_articles)
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'total_collected': len(all_articles),
            'total_unique': len(unique_articles),
            'keywords': keywords,
            'excel_file': None,
            'firebase_uploaded': False
        }
        
        # ì—‘ì…€ ì €ì¥
        if save_excel and unique_articles:
            excel_file = self.save_to_excel(unique_articles)
            result['excel_file'] = excel_file
        
        # Firebase ì—…ë¡œë“œ
        if upload_firebase and unique_articles:
            firebase_success = self.upload_to_firebase(unique_articles)
            result['firebase_uploaded'] = firebase_success
        
        return result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì‹œì‘")
    
    # ìˆ˜ì§‘í•  í‚¤ì›Œë“œ ëª©ë¡
    keywords = ["AI", "ì¸ê³µì§€ëŠ¥", "ê¸°ìˆ ", "ê²½ì œ", "ì£¼ì‹", "ë¶€ë™ì‚°"]
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
    collector = NewsCollector()
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰
    result = collector.collect_news(
        keywords=keywords,
        save_excel=True,
        upload_firebase=True
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
    print(f"  - ì´ ìˆ˜ì§‘: {result['total_collected']}ê°œ")
    print(f"  - ì¤‘ë³µ ì œê±° í›„: {result['total_unique']}ê°œ")
    print(f"  - í‚¤ì›Œë“œ: {', '.join(result['keywords'])}")
    print(f"  - ì—‘ì…€ íŒŒì¼: {result['excel_file']}")
    print(f"  - Firebase ì—…ë¡œë“œ: {'ì„±ê³µ' if result['firebase_uploaded'] else 'ì‹¤íŒ¨'}")
    
    print("\nâœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 