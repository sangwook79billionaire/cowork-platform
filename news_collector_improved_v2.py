#!/usr/bin/env python3
"""
ì‹¤ì œ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘í•˜ëŠ” ê°œì„ ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
"""

import os
import json
import requests
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any
import firebase_admin
from firebase_admin import credentials, firestore
from dotenv import load_dotenv
import hashlib
import re
import time
import random

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class NewsCollectorV2:
    def __init__(self):
        """ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”"""
        self.collected_news = []
        self.firebase_db = None
        self.news_api_key = os.getenv('NEWS_API_KEY')
        self._init_firebase()
    
    def _init_firebase(self):
        """Firebase ì´ˆê¸°í™”"""
        try:
            if not firebase_admin._apps:
                cred = credentials.Certificate("firebase/serviceAccountKey.json")
                firebase_admin.initialize_app(cred)
                print("âœ… Firebase ì—°ê²° ì„±ê³µ")
            self.firebase_db = firestore.client()
        except Exception as e:
            print(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def search_google_news_rss(self, keyword: str, language: str = 'ko') -> List[Dict[str, Any]]:
        """Google News RSSì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” Google News RSS ê²€ìƒ‰ ì‹œì‘: {keyword}")
            
            # Google News RSS URL
            url = f"https://news.google.com/rss/search?q={keyword}&hl={language}&gl=KR&ceid=KR:{language}"
            
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # XML íŒŒì‹± (ê°„ë‹¨í•œ ë°©ì‹)
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.content)
            
            articles = []
            for item in root.findall('.//item'):
                title = item.find('title').text if item.find('title') is not None else ''
                link = item.find('link').text if item.find('link') is not None else ''
                pub_date = item.find('pubDate').text if item.find('pubDate') is not None else ''
                description = item.find('description').text if item.find('description') is not None else ''
                
                # ì†ŒìŠ¤ ì¶”ì¶œ
                source = ''
                source_elem = item.find('source')
                if source_elem is not None:
                    source = source_elem.text or ''
                
                # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ê³ ìœ  ID ìƒì„±
                article_id = hashlib.md5(f"{title}{link}".encode()).hexdigest()
                
                article = {
                    'id': article_id,
                    'title': title,
                    'link': link,
                    'source': source,
                    'published_at': pub_date,
                    'description': description,
                    'keyword': keyword,
                    'collected_at': datetime.now().isoformat()
                }
                
                articles.append(article)
            
            print(f"âœ… Google News RSSì—ì„œ {len(articles)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            return articles
            
        except Exception as e:
            print(f"âŒ Google News RSS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def remove_duplicates(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_articles = []
        
        for article in articles:
            article_id = article['id']
            if article_id not in seen:
                seen.add(article_id)
                unique_articles.append(article)
        
        print(f"ğŸ”„ ì¤‘ë³µ ì œê±°: {len(articles)} â†’ {len(unique_articles)}")
        return unique_articles
    
    def save_to_excel(self, articles: List[Dict[str, Any]], filename: str = None) -> str:
        """ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"news_data_{timestamp}.xlsx"
        
        df = pd.DataFrame(articles)
        df.to_excel(filename, index=False)
        print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    
    def upload_to_firebase(self, articles: List[Dict[str, Any]]) -> bool:
        """Firebase Firestoreì— ì—…ë¡œë“œ"""
        try:
            batch = self.firebase_db.batch()
            collection_ref = self.firebase_db.collection('news')
            
            for article in articles:
                doc_ref = collection_ref.document(article['id'])
                batch.set(doc_ref, article)
            
            batch.commit()
            print(f"âœ… Firebase ì—…ë¡œë“œ ì™„ë£Œ: {len(articles)}ê°œ ë¬¸ì„œ")
            return True
            
        except Exception as e:
            print(f"âŒ Firebase ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def collect_news(self, keywords: List[str], save_excel: bool = True, upload_firebase: bool = True) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜"""
        print("ğŸš€ ì‹¤ì œ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘í•˜ëŠ” ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì‹œì‘")
        
        all_articles = []
        failed_keywords = []
        
        for keyword in keywords:
            try:
                print(f"\nğŸ” í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
                articles = self.search_google_news_rss(keyword)
                
                if articles:
                    all_articles.extend(articles)
                else:
                    failed_keywords.append(keyword)
                    print(f"âŒ í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"âŒ í‚¤ì›Œë“œ '{keyword}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                failed_keywords.append(keyword)
        
        # ì¤‘ë³µ ì œê±°
        unique_articles = self.remove_duplicates(all_articles)
        
        # ê²°ê³¼ ì €ì¥
        excel_file = None
        firebase_uploaded = False
        
        if save_excel and unique_articles:
            excel_file = self.save_to_excel(unique_articles)
        
        if upload_firebase and unique_articles:
            firebase_uploaded = self.upload_to_firebase(unique_articles)
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            'total_collected': len(all_articles),
            'total_unique': len(unique_articles),
            'keywords': keywords,
            'failed_keywords': failed_keywords,
            'excel_file': excel_file,
            'firebase_uploaded': firebase_uploaded,
            'message': 'ë‰´ìŠ¤ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.' if unique_articles else 'ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.'
        }
        
        print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
        print(f"  - ì´ ìˆ˜ì§‘: {result['total_collected']}ê°œ")
        print(f"  - ì¤‘ë³µ ì œê±° í›„: {result['total_unique']}ê°œ")
        print(f"  - ì„±ê³µí•œ í‚¤ì›Œë“œ: {len(keywords) - len(failed_keywords)}ê°œ")
        print(f"  - ì‹¤íŒ¨í•œ í‚¤ì›Œë“œ: {len(failed_keywords)}ê°œ")
        if excel_file:
            print(f"  - ì—‘ì…€ íŒŒì¼: {excel_file}")
        print(f"  - Firebase ì—…ë¡œë“œ: {'ì„±ê³µ' if firebase_uploaded else 'ì‹¤íŒ¨'}")
        
        print("\nâœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
        return result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = NewsCollectorV2()
    
    # ê²€ìƒ‰ í‚¤ì›Œë“œ
    keywords = ["AI", "ì¸ê³µì§€ëŠ¥", "ê¸°ìˆ ", "ê²½ì œ", "ì£¼ì‹", "ë¶€ë™ì‚°"]
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰
    result = collector.collect_news(
        keywords=keywords,
        save_excel=True,
        upload_firebase=True
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print(json.dumps(result, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main() 